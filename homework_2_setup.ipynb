{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70225573-6a63-47b5-9e4e-3311014fe228",
   "metadata": {},
   "source": [
    "# 1. PCA for Network Intrusion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05100ad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T13:44:11.395800Z",
     "start_time": "2025-05-27T13:44:11.389617Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def load_kdd_data(data_dir=\"./datasets/kdd_balanced\"):\n",
    "    data_path = Path(data_dir)\n",
    "    df_main   = pd.read_parquet(data_path / \"balanced_dataset.parquet\")\n",
    "    feature_cols       = [c for c in df_main.columns if c.startswith(\"feature_\")]\n",
    "    D_balanced         = df_main[feature_cols].values\n",
    "    is_normal_balanced = df_main[\"is_normal\"].values\n",
    "    original_indices   = df_main[\"original_index\"].values\n",
    "    df_balanced = None\n",
    "    if (data_path / \"original_data_balanced.parquet\").exists():\n",
    "        df_balanced = pd.read_parquet(data_path / \"original_data_balanced.parquet\")\n",
    "    with open(data_path / \"metadata.json\") as f:\n",
    "        metadata = json.load(f)\n",
    "    print(f\"Loaded balanced data: {D_balanced.shape}, normal={metadata['n_normal']}, intrusion={metadata['n_intrusion']}\")\n",
    "    return D_balanced, is_normal_balanced, original_indices, df_balanced, metadata\n",
    "\n",
    "\n",
    "class PCA:\n",
    "    def __init__(self, n_components: int):\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, X: np.ndarray):\n",
    "        # center\n",
    "        self.mean_ = X.mean(axis=0)\n",
    "        C         = X - self.mean_\n",
    "        # full SVD\n",
    "        U, S, Vt  = np.linalg.svd(C, full_matrices=False)\n",
    "        # truncate\n",
    "        r         = self.n_components\n",
    "        U_r       = U[:, :r]\n",
    "        S_r       = S[:r]\n",
    "        V_rT      = Vt[:r, :]\n",
    "        # store\n",
    "        self.components_ = V_rT.T                # (n_features, r)\n",
    "        self._Y          = U_r * S_r[np.newaxis, :]  # (n_samples, r)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray):\n",
    "        Xc = X - self.mean_\n",
    "        return Xc @ self.components_\n",
    "\n",
    "    def fit_transform(self, X: np.ndarray):\n",
    "        self.fit(X)\n",
    "        return self._Y\n",
    "\n",
    "    def inverse_transform(self, Y: np.ndarray):\n",
    "        return (Y @ self.components_.T) + self.mean_\n",
    "\n",
    "\n",
    "def compute_pca_from_intrusion_data(D: np.ndarray, r: int):\n",
    "    \"\"\"\n",
    "    Train Data on all points, not just on the intrusion dataset.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=r).fit(D)\n",
    "    return pca.components_, pca.mean_\n",
    "\n",
    "\n",
    "def project_to_low_dimensional_space(D: np.ndarray,\n",
    "                                     X_intrusion: np.ndarray,\n",
    "                                     mu_intrusion: np.ndarray):\n",
    "    \"\"\"\n",
    "    Center D with mu_intrusion and project onto intrusion axes.\n",
    "    Returns Y of shape (n_samples, r).\n",
    "    \"\"\"\n",
    "    Dc = D - mu_intrusion[np.newaxis, :]\n",
    "    return Dc @ X_intrusion\n",
    "\n",
    "\n",
    "def reconstruct_from_low_dimensional(Y: np.ndarray,\n",
    "                                     X_intrusion: np.ndarray,\n",
    "                                     mu_intrusion: np.ndarray):\n",
    "    \"\"\"\n",
    "    Reconstruct D ≈ Y @ X_intrusion.T + mu_intrusion.\n",
    "    \"\"\"\n",
    "    return (Y @ X_intrusion.T) + mu_intrusion[np.newaxis, :]\n",
    "\n",
    "\n",
    "def compute_reconstruction_error(original: np.ndarray,\n",
    "                                 reconstructed: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Persample squaredL2 reconstruction error:\n",
    "      error_i = sum_j (original[i,j]  reconstructed[i,j])**2\n",
    "    \"\"\"\n",
    "    diff   = original - reconstructed\n",
    "    return np.sum(diff * diff, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa2795e898f5d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T13:44:18.586799Z",
     "start_time": "2025-05-27T13:44:11.405201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded balanced data: (97378, 118), normal=97278, intrusion=100\n",
      "Low-dim coords of sample 7 (first three):\n",
      "z₀ = -0.099082\n",
      "z₁ = -0.993120\n",
      "z₂ = 0.062970\n",
      "Reconstruction error of 8th point:       3.549354\n",
      "Mean error for intrusion connections:    30.116689\n",
      "Mean error for normal connections:       12.875805\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90th percentile (threshold ≃ 12.6788):\n",
      "  tp_90 = 99\n",
      "  fp_90 = 9639\n",
      "\n",
      "95th percentile (threshold ≃ 19.7437):\n",
      "  tp_95 = 38\n",
      "  fp_95 = 4831\n",
      "\n",
      "99th percentile (threshold ≃ 114.4824):\n",
      "  tp_99 = 2\n",
      "  fp_99 = 972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#load data\n",
    "D_balanced, is_normal_balanced, original_indices, _, metadata = load_kdd_data()\n",
    "\n",
    "r = 10\n",
    "X_full, mu_full = compute_pca_from_intrusion_data(D_balanced, r)\n",
    "\n",
    "Y_all    = project_to_low_dimensional_space(D_balanced, X_full, mu_full)\n",
    "D_hat_all = reconstruct_from_low_dimensional(Y_all, X_full, mu_full)\n",
    "errors   = compute_reconstruction_error(D_balanced, D_hat_all)\n",
    "\n",
    "\n",
    "z = Y_all[7]\n",
    "z0, z1, z2 = z[0], z[1], z[2]\n",
    "\n",
    "print(f\"Low-dim coords of sample 7 (first three):\\n\"\n",
    "      f\"z₀ = {z0:.6f}\\n\"\n",
    "      f\"z₁ = {z1:.6f}\\n\"\n",
    "      f\"z₂ = {z2:.6f}\")\n",
    "\n",
    "error_8 = errors[7]\n",
    "\n",
    "mean_intrusion_error = errors[~is_normal_balanced].mean()\n",
    "mean_normal_error    = errors[is_normal_balanced].mean()\n",
    "\n",
    "print(f\"Reconstruction error of 8th point:       {error_8:.6f}\")\n",
    "print(f\"Mean error for intrusion connections:    {mean_intrusion_error:.6f}\")\n",
    "print(f\"Mean error for normal connections:       {mean_normal_error:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "prediction_percentiles = [90, 95, 99]\n",
    "\n",
    "sorted_errors = np.sort(errors)\n",
    "percentiles = np.linspace(0, 100, len(sorted_errors))\n",
    "\n",
    "#plot sorted errors vs percentiles\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(percentiles, sorted_errors)\n",
    "plt.xlabel(\"Percentile of reconstruction errors\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.title(\"Error vs Percentile\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#log scaled for easier analysis\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(percentiles, sorted_errors)\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"Percentile\")\n",
    "plt.ylabel(\"Reconstruction error (log scale)\")\n",
    "plt.title(\"Error vs Percentile\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# c\n",
    "thresholds = np.percentile(errors, prediction_percentiles)\n",
    "\n",
    "for p, t in zip(prediction_percentiles, thresholds):\n",
    "    preds = errors > t\n",
    "    \n",
    "    tp = np.sum((~is_normal_balanced) & preds)\n",
    "    fp = np.sum(( is_normal_balanced) & preds)\n",
    "    \n",
    "    print(f\"{p}th percentile (threshold ≃ {t:.4f}):\")\n",
    "    print(f\"  tp_{p} = {tp}\")\n",
    "    print(f\"  fp_{p} = {fp}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d77a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def load_iris_data(path=Path(\"datasets/iris/iris.csv\")):\n",
    "    df = pd.read_csv(path)\n",
    "    data = df.iloc[:, :-1].values\n",
    "    labels = df['target'].values\n",
    "    return data, labels\n",
    "\n",
    "def print_iris_info(data, labels):\n",
    "    n_samples, n_features = data.shape\n",
    "    n_classes = len(np.unique(labels))\n",
    "    feature_names = ['sepal length', 'sepal width', 'petal length', 'petal width']\n",
    "\n",
    "    print(f\"Number of samples: {n_samples}\")\n",
    "    print(f\"Number of features: {n_features}\")\n",
    "    print(f\"Number of classes: {n_classes}\")\n",
    "    print(f\"Feature names: {feature_names}\")\n",
    "    print(f\"Class distribution:\")\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    for cls, count in zip(unique, counts):\n",
    "        print(f\"  Class {cls}: {count} samples\")\n",
    "\n",
    "def init_centroids_greedy_pp(D,r,l=10):\n",
    "    '''\n",
    "        :param r: (int) number of centroids (clusters)\n",
    "        :param D: (np-array) the data matrix\n",
    "        :param l: (int) number of centroid candidates in each step\n",
    "        :return: (np-array) 'X' the selected centroids from the dataset\n",
    "    '''   \n",
    "    rng =  np.random.default_rng(seed=RANDOM_SEED) # use this random generator to sample the candidates (sampling according to given probabilities can be done via rng.choice(..))\n",
    "    n,d = D.shape\n",
    "\n",
    "    # Your code here\n",
    "\n",
    "    indexes = rng.integers(low=0, high=n, size=r)\n",
    "    X = np.array(D[indexes,:]).T\n",
    "    return X\n",
    "\n",
    "# K-means implementation from the lecture slides\n",
    "def RSS(D,X,Y):\n",
    "    return np.sum((D- Y@X.T)**2)\n",
    "    \n",
    "def getY(labels):\n",
    "    Y = np.eye(max(labels)+1)[labels]\n",
    "    return Y\n",
    "    \n",
    "def update_centroid(D,Y):\n",
    "    cluster_sizes = np.diag(Y.T@Y).copy()\n",
    "    cluster_sizes[cluster_sizes==0]=1\n",
    "    return D.T@Y/cluster_sizes\n",
    "    \n",
    "def update_assignment(D,X):\n",
    "    dist = np.sum((np.expand_dims(D,2) - X)**2,1)\n",
    "    labels = np.argmin(dist,1)\n",
    "    return getY(labels)\n",
    "    \n",
    "def kmeans(D,r, X_init, epsilon=0.00001, t_max=10000):\n",
    "    X = X_init.copy()\n",
    "    Y = update_assignment(D,X)\n",
    "    rss_old = RSS(D,X,Y) +2*epsilon\n",
    "    t=0\n",
    "    \n",
    "    #Looping as long as difference of objective function values is larger than epsilon\n",
    "    while rss_old - RSS(D,X,Y) > epsilon and t < t_max-1:\n",
    "        rss_old = RSS(D,X,Y)\n",
    "        X = update_centroid(D,Y)\n",
    "        Y = update_assignment(D,X)\n",
    "        t+=1\n",
    "    print(t,\"iterations\")\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "data, labels = load_iris_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b0be9",
   "metadata": {},
   "source": [
    "# 3. Netflix Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8999edd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:59:37.201807Z",
     "start_time": "2025-05-21T12:59:36.986301Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_ratings_data_pandas(data_dir=\"ml-latest-small/\"):\n",
    "    \"\"\"Load data using pandas dataframes.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    assert data_dir.exists(), f\"{data_dir} does not exist\"\n",
    "\n",
    "    return pd.read_csv(data_dir / 'ratings.csv',sep=',')\n",
    "\n",
    "\n",
    "def load_movies_data_pandas(data_dir=\"ml-latest-small/\"):\n",
    "    \"\"\"Load data using pandas dataframes.\"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    assert data_dir.exists(), f\"{data_dir} does not exist\"\n",
    "    return pd.read_csv(data_dir / 'movies.csv')\n",
    "\n",
    "\n",
    "def filter_data(ratings_data: pd.DataFrame, movies_data: pd.DataFrame):\n",
    "    \"\"\"Filter data. Too little ratings prevent effective use of matrix completion.\"\"\"\n",
    "    ratings_data = ratings_data.pivot(\n",
    "        index='userId',\n",
    "        columns='movieId',\n",
    "        values='rating'\n",
    "    ).fillna(0)\n",
    "\n",
    "    keep_movie = (ratings_data != 0).sum(axis=0) > 100\n",
    "    ratings_data = ratings_data.loc[:, keep_movie]\n",
    "\n",
    "    # Filter movies_data by movieId (columns of ratings_data after filtering)\n",
    "    movies_data = movies_data[movies_data['movieId'].isin(ratings_data.columns)]\n",
    "\n",
    "    keep_user = (ratings_data != 0).sum(axis=1) >= 5\n",
    "    ratings_data = ratings_data.loc[keep_user, :]\n",
    "\n",
    "    return ratings_data, movies_data\n",
    "\n",
    "\n",
    "def print_data_summary(ratings: pd.DataFrame):\n",
    "    n_users = ratings.shape[0]\n",
    "    n_movies = ratings.shape[1]\n",
    "    n_ratings = (ratings != 0).sum().sum()\n",
    "    density = n_ratings / (n_users * n_movies)\n",
    "\n",
    "    print(f\"Dataset Summary\")\n",
    "    print(f\"----------------\")\n",
    "    print(f\"Users: {n_users}\")\n",
    "    print(f\"Movies: {n_movies}\")\n",
    "    print(f\"Total Ratings: {n_ratings}\")\n",
    "    print(f\"Data Density: {density:.4f} (fraction of observed ratings)\")\n",
    "\n",
    "\n",
    "def load_ratings_data(data_dir=\"ml-latest-small/\", print_summary=False):\n",
    "    \"\"\"Load data in numpy format.\"\"\"\n",
    "    ratings, movies = filter_data(\n",
    "        load_ratings_data_pandas(data_dir=data_dir),\n",
    "        load_movies_data_pandas(data_dir=data_dir)\n",
    "    )\n",
    "    if print_summary:\n",
    "        print_data_summary(ratings)\n",
    "    return ratings.to_numpy()\n",
    "\n",
    "\n",
    "def matrix_completion(D, n_features, n_movies, n_users, t_max=100, lambd=0.1):\n",
    "    np.random.seed(0)\n",
    "    X = np.random.normal(size=(n_movies, n_features))\n",
    "    Y = np.random.normal(size=(n_users, n_features))\n",
    "\n",
    "    # Implementation the optimization procedure here\n",
    "    raise NotImplementedError\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3e83f2b82e3dccf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T12:59:37.485146Z",
     "start_time": "2025-05-21T12:59:37.387487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Summary\n",
      "----------------\n",
      "Users: 556\n",
      "Movies: 134\n",
      "Total Ratings: 19694\n",
      "Data Density: 0.2643 (fraction of observed ratings)\n"
     ]
    }
   ],
   "source": [
    "ratings = load_ratings_data(\"datasets/ml-latest-small\", print_summary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81460c82",
   "metadata": {},
   "source": [
    "# 4. Image Classification With Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d56288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN Embedding Space Visualization\n",
    "\n",
    "This educational module demonstrates:\n",
    "- ResNet-style architecture with skip connections\n",
    "- Embedding space learning for visualization\n",
    "- Domain transfer between MNIST and Fashion-MNIST\n",
    "- Decision boundary visualization\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Optional, Callable\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration parameters for the model and training.\"\"\"\n",
    "\n",
    "    # Model architecture\n",
    "    embedding_dim: int = 2\n",
    "    num_classes: int = 10\n",
    "\n",
    "    # Training hyperparameters\n",
    "    learning_rate: float = 0.9 \n",
    "    momentum: float = 0.9\n",
    "    weight_decay: float = 5e-4\n",
    "    batch_size: int = 128\n",
    "    epochs: int = 5\n",
    "    dropout_rate_1: float = 0.9\n",
    "    dropout_rate_2: float = 0.9\n",
    "\n",
    "    # Visualization\n",
    "    viz_samples: int = 100\n",
    "    viz_zoom: float = 0.7\n",
    "    grid_resolution: float = 0.1 \n",
    "    \n",
    "    # Paths\n",
    "    checkpoint_dir: Path = Path(\"checkpoint\")\n",
    "    model_filename: str = \"embedding_model.pth\"\n",
    "\n",
    "    @property\n",
    "    def device(self) -> str:\n",
    "        \"\"\"Get the appropriate device for computation.\"\"\"\n",
    "        return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual block with skip connections and grouped convolutions.\n",
    "\n",
    "    Implements: output = input + F(input)\n",
    "    where F is a residual function composed of BatchNorm→ReLU→Conv layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, groups: int = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        groups = min(groups, min(in_channels, out_channels))\n",
    "\n",
    "        # Main convolution pathway\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                              padding=\"same\", groups=groups)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size,\n",
    "                              padding=\"same\", groups=min(groups, out_channels))\n",
    "\n",
    "        # Skip connection (identity or dimension adjustment)\n",
    "        self.skip_connection = (\n",
    "            nn.Identity() if in_channels == out_channels\n",
    "            else nn.Conv2d(in_channels, out_channels, kernel_size=1, padding=\"same\")\n",
    "        )\n",
    "\n",
    "        # Pre-activation normalization layers\n",
    "        self.norm1 = nn.BatchNorm2d(in_channels)\n",
    "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass implementing residual connection.\"\"\"\n",
    "        identity = self.skip_connection(x)\n",
    "\n",
    "        # Residual pathway: BatchNorm → ReLU → Conv → BatchNorm → ReLU → Conv\n",
    "        out = self.conv1(self.relu(self.norm1(x)))\n",
    "        out = self.conv2(self.relu(self.norm2(out)))\n",
    "\n",
    "        return identity + out\n",
    "\n",
    "\n",
    "class EmbeddingNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN that maps input images to low-dimensional embedding space.\n",
    "\n",
    "    Uses global average pooling instead of flattening to reduce overfitting\n",
    "    and make the model robust to different input sizes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim: int, dropout_rate_1: float, dropout_rate_2: float):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initial feature extraction\n",
    "        self.initial_conv = nn.Conv2d(1, 32, kernel_size=5, padding=\"same\")\n",
    "        self.initial_norm = nn.BatchNorm2d(32)\n",
    "\n",
    "        # First residual block set (32 channels, groups=2)\n",
    "        self.res_block1 = ResidualBlock(32, 32, kernel_size=3, groups=2)\n",
    "        self.res_block2 = ResidualBlock(32, 32, kernel_size=3, groups=2)\n",
    "\n",
    "        # Spatial downsampling\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.norm_after_pool = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Second residual block set (64 channels, groups=4)\n",
    "        self.res_block3 = ResidualBlock(32, 64, kernel_size=3, groups=4)\n",
    "        self.res_block4 = ResidualBlock(64, 64, kernel_size=3, groups=4)\n",
    "\n",
    "        # Final processing\n",
    "        self.final_norm = nn.BatchNorm1d(64)\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, embedding_dim)\n",
    "\n",
    "        # Regularization\n",
    "        self.dropout1 = nn.Dropout(dropout_rate_1)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate_2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass mapping images to embedding space.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, 1, 28, 28)\n",
    "\n",
    "        Returns:\n",
    "            Embedding tensor of shape (batch_size, embedding_dim)\n",
    "        \"\"\"\n",
    "        out = F.relu(self.initial_norm(self.initial_conv(x)))\n",
    "\n",
    "        # out.shape = ? (tensor shape 1)\n",
    "\n",
    "        # First round of residual blocks\n",
    "        out = self.res_block2(self.res_block1(out))\n",
    "\n",
    "        # out.shape = ? (tensor shape 2)\n",
    "\n",
    "        # Pooling\n",
    "        out = self.norm_after_pool(self.pool(out))\n",
    "\n",
    "        # out.shape = ? (tensor shape 3)\n",
    "\n",
    "        # Second round of residual blocks\n",
    "        out = self.res_block4(self.res_block3(out))\n",
    "\n",
    "        # out.shape = ? (tensor shape 4)\n",
    "\n",
    "        # Global average pooling\n",
    "        out = torch.mean(out, dim=(-1, -2))\n",
    "        out = self.final_norm(out)\n",
    "\n",
    "        # out.shape = ? (tensor shape 5)\n",
    "\n",
    "        # Map to embedding space\n",
    "        out = self.dropout1(out)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = self.dropout2(out)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    \"\"\"Complete model combining embedding network with classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim: int, num_classes: int, config: Config):\n",
    "        super().__init__()\n",
    "        self.embedding_net = EmbeddingNetwork(\n",
    "            embedding_dim, config.dropout_rate_1, config.dropout_rate_2\n",
    "        )\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes, bias=True)\n",
    "\n",
    "        nn.init.normal_(self.classifier.weight, 0, 0.01)\n",
    "        nn.init.constant_(self.classifier.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass for training and evaluation.\"\"\"\n",
    "        embeddings = self.embedding_net(x)\n",
    "        return self.classifier(embeddings)\n",
    "\n",
    "    def get_embeddings(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Extract embeddings for visualization.\"\"\"\n",
    "        return self.embedding_net(x)\n",
    "\n",
    "    def get_probabilities(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Get class probabilities for confidence visualization.\"\"\"\n",
    "        embeddings = self.embedding_net(x)\n",
    "        return F.softmax(self.classifier(embeddings), dim=1)\n",
    "\n",
    "\n",
    "def create_data_loaders(dataset_class, config: Config) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"\n",
    "    Create training and test data loaders.\n",
    "\n",
    "    Args:\n",
    "        dataset_class: torchvision dataset class (MNIST or FashionMNIST)\n",
    "        config: Configuration object\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (train_loader, test_loader)\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))  # MNIST standard values\n",
    "    ])\n",
    "\n",
    "    # Training data\n",
    "    train_dataset = dataset_class(root='./data', train=True, download=True, transform=transform)\n",
    "    if config.num_classes < 10:\n",
    "        mask = train_dataset.targets < config.num_classes\n",
    "        train_dataset.targets = train_dataset.targets[mask]\n",
    "        train_dataset.data = train_dataset.data[mask]\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    # Test data\n",
    "    test_dataset = dataset_class(root='./data', train=False, download=True, transform=transform)\n",
    "    if config.num_classes < 10:\n",
    "        mask = test_dataset.targets < config.num_classes\n",
    "        test_dataset.targets = test_dataset.targets[mask]\n",
    "        test_dataset.data = test_dataset.data[mask]\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EpochMetrics:\n",
    "    \"\"\"Container for epoch training/evaluation metrics.\"\"\"\n",
    "    accuracy: float\n",
    "    avg_confidence: float\n",
    "    avg_loss: float\n",
    "    total_samples: int\n",
    "    elapsed_time: Optional[float] = None\n",
    "\n",
    "\n",
    "def compute_batch_metrics(logits: torch.Tensor, targets: torch.Tensor, loss: torch.Tensor) -> Tuple[int, float, int]:\n",
    "    \"\"\"\n",
    "    Compute metrics for a single batch.\n",
    "\n",
    "    Args:\n",
    "        logits: Model output logits\n",
    "        targets: Ground truth labels\n",
    "        loss: Computed loss for the batch\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (correct_predictions, total_confidence, batch_size)\n",
    "    \"\"\"\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    confidences, predictions = probabilities.max(1)\n",
    "\n",
    "    correct_predictions = predictions.eq(targets).sum().item()\n",
    "    total_confidence = confidences.sum().item()\n",
    "    batch_size = targets.size(0)\n",
    "\n",
    "    return correct_predictions, total_confidence, batch_size\n",
    "\n",
    "\n",
    "def run_epoch(\n",
    "    model: nn.Module,\n",
    "    criterion,\n",
    "    data_loader: DataLoader,\n",
    "    device: str,\n",
    "    optimizer=None,\n",
    "    is_training: bool = True\n",
    ") -> EpochMetrics:\n",
    "    \"\"\"\n",
    "    Run one epoch of training or evaluation.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        criterion: Loss function\n",
    "        data_loader: Data loader\n",
    "        device: Device to run on\n",
    "        optimizer: Optimizer (required if is_training=True)\n",
    "        is_training: Whether to run in training mode\n",
    "\n",
    "    Returns:\n",
    "        EpochMetrics containing all computed metrics\n",
    "    \"\"\"\n",
    "    if is_training:\n",
    "        if optimizer is None:\n",
    "            raise ValueError(\"Optimizer required for training mode\")\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_confidence = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "    context_manager = torch.no_grad() if not is_training else torch.enable_grad()\n",
    "\n",
    "    with context_manager:\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            if is_training:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "            if torch.isnan(loss):\n",
    "                print(\"Warning: NaN loss detected\")\n",
    "\n",
    "            if is_training:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            # Compute batch metrics (always without gradients for metrics)\n",
    "            with torch.no_grad():\n",
    "                batch_correct, batch_confidence, batch_size = compute_batch_metrics(logits, targets, loss)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                total_correct += batch_correct\n",
    "                total_confidence += batch_confidence\n",
    "                total_samples += batch_size\n",
    "\n",
    "    # Calculate final metrics\n",
    "    if total_samples == 0:\n",
    "        print(\"Warning: No samples processed\")\n",
    "        return EpochMetrics(0, 0, float('inf'), 0, time.time() - start_time)\n",
    "\n",
    "    accuracy = 100.0 * total_correct / total_samples\n",
    "    avg_confidence = 100.0 * total_confidence / total_samples\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    return EpochMetrics(\n",
    "        accuracy=accuracy,\n",
    "        avg_confidence=avg_confidence,\n",
    "        avg_loss=avg_loss,\n",
    "        total_samples=total_samples,\n",
    "        elapsed_time=elapsed_time\n",
    "    )\n",
    "\n",
    "\n",
    "def train_epoch(model: nn.Module, criterion, optimizer, data_loader: DataLoader, device: str) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Train model for one epoch.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (accuracy, average_confidence)\n",
    "    \"\"\"\n",
    "    metrics = run_epoch(model, criterion, data_loader, device, optimizer, is_training=True)\n",
    "\n",
    "    print(f'Train - Loss: {metrics.avg_loss:.3f} | '\n",
    "          f'Acc: {metrics.accuracy:.3f}% ({int(metrics.accuracy * metrics.total_samples / 100)}/{metrics.total_samples}) | '\n",
    "          f'Conf: {metrics.avg_confidence:.2f}% | Time: {metrics.elapsed_time:.2f}s')\n",
    "\n",
    "    return metrics.accuracy, metrics.avg_confidence\n",
    "\n",
    "\n",
    "def evaluate_model(model: nn.Module, criterion, data_loader: DataLoader, device: str) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate model on test data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (accuracy, average_confidence)\n",
    "    \"\"\"\n",
    "    metrics = run_epoch(model, criterion, data_loader, device, optimizer=None, is_training=False)\n",
    "\n",
    "    print(f'Test  - Loss: {metrics.avg_loss:.3f} | '\n",
    "          f'Acc: {metrics.accuracy:.3f}% ({int(metrics.accuracy * metrics.total_samples / 100)}/{metrics.total_samples}) | '\n",
    "          f'Conf: {metrics.avg_confidence:.2f}%')\n",
    "\n",
    "    return metrics.accuracy, metrics.avg_confidence\n",
    "\n",
    "\n",
    "def save_model(model: nn.Module, accuracy: float, config: Config) -> None:\n",
    "    \"\"\"Save model checkpoint.\"\"\"\n",
    "    config.checkpoint_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'accuracy': accuracy,\n",
    "        'config': {\n",
    "            'embedding_dim': config.embedding_dim,\n",
    "            'num_classes': config.num_classes,\n",
    "            'dropout_rate_1': config.dropout_rate_1,\n",
    "            'dropout_rate_2': config.dropout_rate_2,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    save_path = config.checkpoint_dir / config.model_filename\n",
    "    torch.save(checkpoint, save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n",
    "\n",
    "\n",
    "def load_model(config: Config) -> EmbeddingClassifier:\n",
    "    \"\"\"Load model from checkpoint.\"\"\"\n",
    "    load_path = config.checkpoint_dir / config.model_filename\n",
    "\n",
    "    model = EmbeddingClassifier(config.embedding_dim, config.num_classes, config)\n",
    "    checkpoint = torch.load(load_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"Model loaded from {load_path}\")\n",
    "    print(f\"Loaded model accuracy: {checkpoint['accuracy']:.2f}%\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_decision_boundary(\n",
    "    model: EmbeddingClassifier,\n",
    "    bounds: Tuple[float, float, float, float],\n",
    "    config: Config,\n",
    "    show_classes: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot decision boundary or confidence map in embedding space.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        bounds: (x_min, x_max, y_min, y_max) for plot region\n",
    "        config: Configuration object\n",
    "        show_classes: If True, show class assignments; if False, show confidence\n",
    "    \"\"\"\n",
    "    x_min, x_max, y_min, y_max = bounds\n",
    "\n",
    "    if not all(np.isfinite([x_min, x_max, y_min, y_max])):\n",
    "        print(\"Warning: Invalid bounds detected, using default range\")\n",
    "        x_min, x_max, y_min, y_max = -10, 10, -10, 10\n",
    "\n",
    "    if x_max <= x_min:\n",
    "        x_max = x_min + 10\n",
    "    if y_max <= y_min:\n",
    "        y_max = y_min + 10\n",
    "\n",
    "    x = np.arange(x_min, x_max, config.grid_resolution, dtype=np.float32)\n",
    "    y = np.arange(y_min, y_max, config.grid_resolution, dtype=np.float32)\n",
    "\n",
    "    if len(x) == 0 or len(y) == 0:\n",
    "        print(\"Warning: Empty grid, adjusting resolution\")\n",
    "        x = np.linspace(x_min, x_max, 50, dtype=np.float32)\n",
    "        y = np.linspace(y_min, y_max, 50, dtype=np.float32)\n",
    "\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "    # Create grid points for evaluation\n",
    "    grid_points = torch.from_numpy(\n",
    "        np.array([xx.ravel(), yy.ravel()]).T\n",
    "    ).float().to(config.device)\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        probabilities = torch.softmax(model.classifier(grid_points), dim=1)\n",
    "        probabilities = probabilities.cpu().numpy()\n",
    "\n",
    "    # Reshape for contour plotting\n",
    "    if show_classes:\n",
    "        class_assignments = probabilities.argmax(axis=1).reshape(xx.shape)\n",
    "        plt.contourf(xx, yy, class_assignments, levels=config.num_classes, cmap='tab10', alpha=0.7)\n",
    "        plt.colorbar(label='Predicted Class')\n",
    "    else:\n",
    "        confidence_map = probabilities.max(axis=1).reshape(xx.shape)\n",
    "        contour = plt.contourf(xx, yy, confidence_map, levels=20, cmap='viridis', alpha=0.7)\n",
    "        plt.clim(0, 1)\n",
    "        plt.colorbar(contour, label='Max Confidence')\n",
    "\n",
    "    plt.axis('equal')\n",
    "\n",
    "\n",
    "def scatter_images_on_embeddings(\n",
    "    images: torch.Tensor,\n",
    "    embeddings: torch.Tensor,\n",
    "    config: Config\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Scatter actual images at their embedding coordinates.\n",
    "\n",
    "    Args:\n",
    "        images: Input images tensor\n",
    "        embeddings: Corresponding embedding coordinates\n",
    "        config: Configuration object\n",
    "    \"\"\"\n",
    "    num_samples = min(images.shape[0], config.viz_samples)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        image = images[i].squeeze().cpu().numpy()\n",
    "        embedding_pos = (embeddings[i, 0].item(), embeddings[i, 1].item())\n",
    "\n",
    "        if not all(np.isfinite(embedding_pos)):\n",
    "            continue\n",
    "\n",
    "        offset_image = OffsetImage(image, cmap=\"gray\", zoom=config.viz_zoom)\n",
    "        annotation_box = AnnotationBbox(\n",
    "            offset_image, embedding_pos, xycoords='data', frameon=False, alpha=0.7\n",
    "        )\n",
    "        plt.gca().add_artist(annotation_box)\n",
    "\n",
    "\n",
    "def visualize_embedding_space(\n",
    "    model: EmbeddingClassifier,\n",
    "    data_loader: DataLoader,\n",
    "    config: Config,\n",
    "    title: str = \"Embedding Space Visualization\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create comprehensive visualization of embedding space.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model\n",
    "        data_loader: Data loader for visualization\n",
    "        config: Configuration object\n",
    "        title: Plot title\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Get batch of data and embeddings\n",
    "    inputs, _ = next(iter(data_loader))\n",
    "    inputs = inputs.to(config.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_embeddings(inputs).cpu()\n",
    "\n",
    "    valid_embeddings = embeddings[torch.isfinite(embeddings).all(dim=1)]\n",
    "\n",
    "    if len(valid_embeddings) == 0:\n",
    "        print(\"Warning: No valid embeddings found, using default bounds\")\n",
    "        bounds = (-10, 10, -10, 10)\n",
    "    else:\n",
    "        margin = 3\n",
    "        x_vals = valid_embeddings[:, 0]\n",
    "        y_vals = valid_embeddings[:, 1]\n",
    "\n",
    "        bounds = (\n",
    "            float(x_vals.min() - margin),\n",
    "            float(x_vals.max() + margin),\n",
    "            float(y_vals.min() - margin),\n",
    "            float(y_vals.max() + margin)\n",
    "        )\n",
    "\n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plot_decision_boundary(model, bounds, config)\n",
    "    scatter_images_on_embeddings(inputs.cpu(), embeddings, config)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Embedding Dimension 1')\n",
    "    plt.ylabel('Embedding Dimension 2')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d90146b-527a-4670-aa59-61a16bf28273",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Main training and evaluation pipeline.\"\"\"\n",
    "# Edit configuration here like so\n",
    "config = Config(\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "print(\"CNN Embedding Space Learning\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Using device: {config.device}\")\n",
    "\n",
    "# Create data loaders\n",
    "print(\"\\nPreparing MNIST data...\")\n",
    "mnist_train_loader, mnist_test_loader = create_data_loaders(datasets.MNIST, config)\n",
    "\n",
    "# Create and setup model\n",
    "print(\"Building model...\")\n",
    "model = EmbeddingClassifier(config.embedding_dim, config.num_classes, config)\n",
    "model = model.to(config.device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    momentum=config.momentum,\n",
    "    weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "# Training loop\n",
    "print(\"\\nTraining...\")\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(config.epochs):\n",
    "    print(f'\\nEpoch {epoch + 1}/{config.epochs}:')\n",
    "    train_epoch(model, criterion, optimizer, mnist_train_loader, config.device)\n",
    "    test_acc, _ = evaluate_model(model, criterion, mnist_test_loader, config.device)\n",
    "\n",
    "    if test_acc > best_accuracy:\n",
    "        best_accuracy = test_acc\n",
    "\n",
    "# Save model\n",
    "save_model(model, best_accuracy, config)\n",
    "\n",
    "# Visualize MNIST embeddings\n",
    "print(\"\\nVisualizing MNIST embeddings...\")\n",
    "try:\n",
    "    visualize_embedding_space(model, mnist_test_loader, config, \"MNIST Embedding Space\")\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Visualization error: {e}\")\n",
    "\n",
    "# Domain transfer experiment\n",
    "print(\"\\nTesting domain transfer with Fashion-MNIST...\")\n",
    "fashion_train_loader, fashion_test_loader = create_data_loaders(datasets.FashionMNIST, config)\n",
    "\n",
    "fashion_acc, _ = evaluate_model(model, criterion, fashion_test_loader, config.device)\n",
    "\n",
    "# Visualize Fashion-MNIST embeddings\n",
    "try:\n",
    "    visualize_embedding_space(\n",
    "        model, fashion_test_loader, config,\n",
    "        \"Fashion-MNIST Embeddings (MNIST-trained Model)\"\n",
    "    )\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Visualization error: {e}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\nResults Summary:\")\n",
    "print(f\"MNIST Test Accuracy: {best_accuracy:.2f}%\")\n",
    "print(f\"Fashion-MNIST Accuracy: {fashion_acc:.2f}%\")\n",
    "print(f\"Domain Transfer Gap: {best_accuracy - fashion_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
